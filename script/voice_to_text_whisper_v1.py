import os
import datetime
import argparse
from openai import OpenAI
import pyaudio
import wave
import io
# numpy ya no es necesario si no se usa directamente para manipulaci√≥n de arrays de audio
# import numpy as np
import tempfile # Para crear archivos temporales

# Carga las variables de entorno desde el archivo .env
# Aseg√∫rate de que tu archivo .env est√© en la ra√≠z del proyecto
# y contenga OPENAI_API_KEY="tu_clave_api_aqui"
from dotenv import load_dotenv
load_dotenv()

# Define el directorio por defecto para guardar las transcripciones
script_dir = os.path.dirname(os.path.abspath(__file__))
default_output_dir = os.path.join(script_dir, "..", "input_text")


def transcribe_voice_input_whisper_direct_pyaudio(output_dir=default_output_dir, language="es"):
    """
    Captura audio del micr√≥fono directamente con PyAudio, lo transcribe a texto
    usando OpenAI Whisper API, guarda la transcripci√≥n en un √∫nico archivo .txt
    y elimina el archivo WAV temporal.

    Args:
        output_dir (str): Directorio donde se guardar√° el archivo de texto transcrito.
                        
        language (str): Idioma para la transcripci√≥n (ej. 'es' para espa√±ol, 'en' para ingl√©s).
                        Nota: Whisper usa c√≥digos de idioma ISO-639-1 (ej. 'es', 'en').
    """
    # Asegura que el directorio de salida exista
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        print(f"Directorio creado: {output_dir}")

    # Inicializa el cliente de OpenAI (la clave API se toma de OPENAI_API_KEY en el entorno)
    try:
        client = OpenAI()
    except Exception as e:
        print(f"‚ùå Error al inicializar el cliente de OpenAI. Aseg√∫rate de que la variable de entorno OPENAI_API_KEY est√© configurada correctamente. Detalles: {e}")
        return

    # Par√°metros de grabaci√≥n
    CHUNK = 1024
    FORMAT = pyaudio.paInt16
    CHANNELS = 1 # Whisper prefiere audio mono
    RATE = 16000 # Frecuencia de muestreo (16 kHz es un buen balance para voz y Whisper)
    RECORD_SECONDS = 10 # Grabar por 10 segundos

    p = pyaudio.PyAudio()

    print("\n--- Prototipo de Entrada por Voz (Whisper API - PyAudio Directo) ---")
    print("Iniciando grabaci√≥n... Di tu orden de voz.")

    # Abre el stream de audio para la grabaci√≥n
    stream = p.open(format=FORMAT,
                    channels=CHANNELS,
                    rate=RATE,
                    input=True,
                    frames_per_buffer=CHUNK)

    frames = []

    # Lee datos del stream de audio durante el tiempo especificado
    for _ in range(0, int(RATE / CHUNK * RECORD_SECONDS)):
        try:
            data = stream.read(CHUNK)
            frames.append(data)
        except IOError as e:
            # Manejo de error si el stream de audio se interrumpe
            print(f"‚ö†Ô∏è Advertencia: Error durante la lectura del stream de audio: {e}")
            break # Sale del bucle de grabaci√≥n si hay un error

    print("Grabaci√≥n finalizada. Procesando audio...")

    # Detiene y cierra el stream de audio
    stream.stop_stream()
    stream.close()
    p.terminate()

    # Define la ruta del archivo WAV temporal que se enviar√° a Whisper
    temp_wav_path = None
    # Define la ruta del archivo de texto de salida √∫nico (siempre el mismo nombre)
    output_txt_filename = os.path.join(output_dir, "order.txt")

    try:
        # Crea un archivo WAV temporal en disco para asegurar la compatibilidad con Whisper API
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp_file:
            temp_wav_path = temp_file.name
            wf = wave.open(temp_wav_path, 'wb')
            wf.setnchannels(CHANNELS)
            wf.setsampwidth(p.get_sample_size(FORMAT))
            wf.setframerate(RATE)
            wf.writeframes(b''.join(frames)) # Escribe todos los frames capturados
            wf.close()
        # print(f"üé∂ Audio capturado temporalmente en: {temp_wav_path}") # L√≠nea de depuraci√≥n opcional

        # Abre el archivo WAV temporal en modo binario de lectura para pas√°rselo a Whisper
        with open(temp_wav_path, "rb") as audio_file_for_whisper:
            # Realiza la transcripci√≥n usando la API de OpenAI Whisper
            transcription = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file_for_whisper, # Pasa el objeto archivo
                language=language            # Especifica el idioma para mejorar la precisi√≥n
            )
            text = transcription.text
            print(f"‚úÖ Texto transcrito por Whisper: \"{text}\"")

        # Guarda la transcripci√≥n en el archivo .txt fijo (sobrescribe el contenido anterior)
        with open(output_txt_filename, "w", encoding="utf-8") as f:
            f.write(text)
        print(f"üíæ Transcripci√≥n guardada en: {output_txt_filename}")

    except Exception as e:
        print(f"‚ùå Ocurri√≥ un error al transcribir con Whisper API: {e}")
    finally:
        # Aseg√∫rate de eliminar el archivo WAV temporal si existe
        if temp_wav_path and os.path.exists(temp_wav_path):
            os.remove(temp_wav_path)
            # print(f"üóëÔ∏è Archivo WAV temporal eliminado: {temp_wav_path}") # L√≠nea de depuraci√≥n opcional


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Prototipo de entrada de voz a texto usando OpenAI Whisper API para PLCaid.")
    parser.add_argument("--output_dir", type=str, default=default_output_dir,
        help="Directorio donde se guardar√°n las transcripciones de texto.")
    parser.add_argument("--lang", type=str, default="es",
                        help="Idioma para la transcripci√≥n (c√≥digo ISO-639-1, ej. 'es', 'en').")

    args = parser.parse_args()

    transcribe_voice_input_whisper_direct_pyaudio(output_dir=args.output_dir, language=args.lang)
    print("\n--- Prototipo de Entrada por Voz (Whisper API) Finalizado ---")